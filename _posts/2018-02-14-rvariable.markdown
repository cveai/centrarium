---
layout: post
title:  "확률변수를 이해하다"
date:   2018-02-02 23:47:00
author: 장승환
categories: 기계학습
tags: 강화학습 RL 확률론 확률 확률변수 
---

불확실성이 포함된 상황을 체계적으로 기술하기 위해 수학의 **확률**이란 개념을 이용하게 된다.
작년 이맘때쯤 확률이라는 개념이 어떻게 탄생하게 되었는지 그 역사적 배경에 관련된 김민형 교수님의 공개강연이 있었다. 
고맙게도 온라인 상에 동영상이 올라와 있으니 한번 시청을 권한다[2].
강연의 내용 중 인상깊었던 것 하나는 확률 개념이 탄생하던 17세기 유럽 그 시대의 석학들에게도 난제였던 문제를
이 시대 우리들은 고등학생들도 그리 어렵지 않게 해결하는 수준이 되었다는 내용이다. 
그래서 우리는 자부심을 좀 가져도 된다는.

확률론이 엄밀한 학문으로 확립된 것은 Kolmogorov


확률 개념을 본격적으로 살펴보기 전에 먼저 고려해야 하는 것이 **이산**과 **연속**의 구분이다.
측도론(measure theory)라는 수학 이론을 이용하면 이산(discrete)과 연속(continuous)의 확률 개념을
통합적으로 다루는 것이 가능하지만, 이 포스트에서는 이산의 경우만을 다루기로 한다.


#### 확률함수와 확률변수

확률에 관련된 논의는 확률이라는 함수로부터 시작하는 것이 좋을 것 같다. "확률"이란 단어는 특정한 성질을 만족하는 함수라는 수학적 개념은 물론 보다 일반적인 의미로도 사용되기 떄문에 이 글에서는 확률함수라는 이름으로 수학적 확률 개념을 지칭하기로 한다.
**확률함수**는 특정조건을 만족하는 $p: \Omega \rightarrow [0,1]$ 형태의 함수인데 $\Omega$를 표본공간(smaple space), 표본공간의 원소를 표본(sample)이라고 한다. 
측도론의 관점에서는 확률함수를 확률 질량 함수 (probability mass function, PMF)라 부른다.
측도론을 이용한 통합적인 접급법은 다음의 동영상을 강의를 추천한다: [3].

일반적으로 주사위를 던져 눈을 관찰하는 경우의 확률론적 모델을 생각해보면 해당되는 확률함수 
$p:\\{ ⚀, ⚁, ⚂, ⚃, ⚄, ⚅ \\} \rightarrow [0,1]$의 함수값은 다음과 같이 정의될 것이다:

$$
p(⚀) = 1/6;  \\
p(⚁) = 1/6;  \\
p(⚂) = 1/6;  \\
p(⚃) = 1/6;  \\
p(⚄) = 1/6;  \\
p(⚅) = 1/6.  \\
$$

즉, 각각의 표본에 대해 $1$보다 작은 어떤 숫자를 대응시킨 것이 확률함수이다.
(이 숫자들의 합이 $1$이 되게 해야한다는 사실은 이미 알고 있을 것이다.)
우리는 주사위를 던지는 시행을 (충분히 반복)했을 때 각 눈이 나오는 "빈도"로 이 숫자를 해석한다.
물론 현실에서 주사위를 아무리 많이 던져도 적확히 확률함수가 지칭하는대로 사건이 일어나지는 않겠지만, 
충분히 공감가능한 한 기준을 제시해주는 것은 분명하다.

많은 경우 이 확률함수를 테이블로 나타내기도 한다.

*테이블*

확률함수라가 나타내는 정보를 한분에 파악하기에 가장 좋은 것은 아무래도 함수의 그래프를 통해서가 아닐까 싶다.
주사위 실험의 경우를 그래프로 나타내면 다음과 같다.

*그래프*

그래프를 보는 순간 당신의 머릿속에는 "분포"라는 단어가 스쳐지나갔을지도 모르겠다.
이와 관련된 내용은 잠시 후에 살펴보기로 하겠다.

확률함수가 주어진 후의 논리 전개 및 관련 계산은 대부분 확률변수라는 개념을 통해 이루어진다. 확률변수의 정의는 간단한다. 표본공간에서 실수로 가는 형태의 함수 $X: \Omega \rightarrow {\mathbb R}$라면 어떤 것이라도 **확률변수**이다. 엄청나게 다양하고 무한히 많은 확률변수가 존재함을 알 수 있을 것이다. 곧 “이 많은 확률함수들로 도대체 무얼 할까?”하는 질문이 떠오를 수도 있는데, 대부분은 창고 속에 묻어두고 인간의 인지능력에 의미있게 다가오는 한줌의 확률변수만을 이용하게 된다. 

먼저 확률변수의 가면을 쓰고 재등장하게 되는 확률함수를 맞이해보자. 앞에서의 주사위 실험과 관련하여 확률변수 $X$를 다음과 같이 정의해보자. 

$$
X : \Omega \rightarrow {\mathbb R} \\
X(⚀) = 1; \\
X(⚁) = 2; \\
X(⚂) = 3; \\
X(⚃) = 4; \\
X(⚄) = 5; \\
X(⚅) = 6.
$$

확률변수 $X$가 의미하는 바를 알아챘는가? 그렇다. $X(\square)$ 는 $\square$가 나타내는 주사위 눈의 갯수이다. 이 $X$라는 확률변수를 이용하면 주사위 실험에서 일어나는 사건(event)들을 간편하게 기술할 수 있다. 예를 들어 $[X = 1]$는 확률변수 $X$의 함수값이 1이 되게 하는 표본을 모두 모은 집합이다.
즉, $[X = 1] = \\{ a \in \Omega : X(a) = 1 \\} = \\{ ⚀ \\}$이다. 
그러면 $\\{ ⚁, ⚂\\}$는 $X$를 이용하여 어떻게 표현수 있을까?
그렇다. $\\{ ⚁, ⚂\\} = [X = 2, 3]$이 된다는 것을 금방 알아차렸을 것이다. 하지만 뭔가 대단한 것을 해낸 것 같지는 않다. 
조금 더 “쓸모있을 지 모르는” 확률변수를 하나 정의해 보자. 

$$
Y(⚀) = 1; \\
Y(⚁) = 0; \\
Y(⚂) = 1; \\
Y(⚃) = 0; \\
Y(⚄) = 1; \\
Y(⚅) = 0.
$$

그러면 $[Y = 1] = \\{a \in \Omega : Y(a) = 1\\}$는 표본중에 확률변수 $Y$에 대한 함수값이 1인 것들로 모인 집합이다. 다르게 말해면 홀수의 눈이 나오는 사건이다. 

사실 [X = 1,2 or 3] = [Y = 1]
생각하기에 따라 편하지 않은가?
사실 중요한 것이 확률변수를 간의 관계

결론적으로는 확률함수가 주어지면 무수히 많은 확률변수가 주어지는데 개별 확률변수는 또다른 확률함수를 생성하게 된다다. 예를 계속 들면, 
p_X = p, 
p_Y[Y = 1] = 1/2
p_Y[Y = 0] = 1/2

**연습문제:** 두 확률함수 p와 p_X 사이의 관계는 무엇인지 생각해보라.


곰곰히 생각해보면 방정식이 정의하는 도형 혹은 부등식의 영역과 유사한 느낌이 있다.


P[] / Pr[] 의 문제


#### 확률분포란 무엇인가?

그러면 확률에서의 분포란 무엇을 뜻하는 말일까? 





#### 기댓값과 분산 : 확률변수들 간의 연산 및 합성함수

확률변수의 장점 중 하나는 확률변수간의 연산을 할 수 있다는 것. 

선형성(linearity):

$${\mathbb E}(X + Y) = {\mathbb E}(X) + {\mathbb E}(Y)$$

$${\mathbb E}(aX) = a{\mathbb E}(X)$$

기댓값 정의

분산 정의

관련 성질


#### 악의 축 : 결합 분포 (Joint distribution)와 주변 분포 (marginal distribution)

확률함수가 오직 하나만 관련되는 경우 확률변수의 유용성은 사실 그렇게 뛰어나 보이지 않습니다. 두개 이상의 확률함수가 관여되는 상황을 생각하기 시작할때 확률변수는 진정한 힘을 발휘하게 된다. 

빛을 발하게 된다. 

두 확률변수 $X$와 $Y$에 대한 결합 확률함수 (결합 확률 질량 함수)는 다음과 보통 다음과 같이 정의됩니다.

$$p_{XY}(x, y) := $P[X=x, Y=y]$$

이 지점에서 확률에 관한 굉장한 혼돈이 시작된다. 과연 $[X=x, Y=y]$의 정체는 무엇일까?



#### 삼위일체 : 확률변수, 확률함수, 그리고 확률분포

<figure>
<img src="/assets/pics/rvariable/trinity.jpg" alt="Trinity" style="width: 35%; height: 35%">
<figcaption>Trinity (사진 출처: <a href="https://en.wikipedia.org/wiki/Trinity_(The_Matrix)">Wikipedia</a>)
</figcaption>
</figure>

확률이야말로 다양하고 상대적으로 통일되지 못한 표기법으로 불필요한 혼란을 많이 읽으키는 주제이다.
이문제를 잘 피해가면서 수식이 나타내는 핵심을 빠르게 이해하기 위한 한가지 방편은 다음 세가지가 사실은 한가지 존재에 대한 다른 표현에 지나지 않는다는 것을 인식하는 것이다:
- 확률분포
- 확률함수 $p$
- 확률변수 $X$

이 세가지 개념이 어떻게 연결되어 있는지 살펴보자. 
먼저, 확률분포를 주기 위해서는 보통 확률함수를 알려주면 된다. 
예를들어 주사위를 던져 눈의 갯수를 확인하는 실험을 모델링하는 확률분포에 대한 정보는 앞에서 보았던 함수 
$p:\\{ ⚀, ⚁, ⚂, ⚃, ⚄, ⚅ \\} \rightarrow [0,1]$, \\
$$
p(⚀) = 1/6;  \\
p(⚁) = 1/6;  \\
p(⚂) = 1/6;  \\
p(⚃) = 1/6;  \\
p(⚄) = 1/6;  \\
p(⚅) = 1/6.  \\
$$
를 알려주는 것으로 충분하다.
이렇게 주어진 확률함수 $p$에 대해 가장 자연스럽게 생각할 수 있은 확률변수 $X$를 다음과 같이 정의했었다:
$$X : \\{ ⚀, ⚁, ⚂, ⚃, ⚄, ⚅ \\} \rightarrow {\mathbb R}\\
X(⚀) = 1; \\
X(⚁) = 2; \\
X(⚂) = 3; \\
X(⚃) = 4; \\
X(⚄) = 5; \\
X(⚅) = 6.
$$
그런데 확률변수 $X$는 다음과 같은 확률함수 $p_X$를 정의한다:
$p_X:\\{ 1, 2, 3, 4, 5, 6 \\} \rightarrow [0,1]$, \\
$$
p_X(1) = 1/6;  \\
p_X(2) = 1/6;  \\
p_X(3) = 1/6;  \\
p_X(4) = 1/6;  \\
p_X(5) = 1/6;  \\
p_X(6) = 1/6.  \\
$$
자 어떤가, 두 확률함수 $p$와 $p_X$는 어떤 관계를 가지는가? 잠시만 들여다 보면 두 확률함수는 본질적으로 같다는 것을 알 수 있을 것이다.
단지 주사위 눈 그림 대신 그에 해당하는 숫자로 표현을 바꿨을 뿐이다.
사실 처음부터 $p$라는 함수를 

$$p:\{ 1, 2, 3, 4, 5, 6 \} \rightarrow [0,1]$$  
$$
p(1) = 1/6;  \\
p(2) = 1/6;  \\
p(3) = 1/6;  \\
p(4) = 1/6;  \\
p(5) = 1/6;  \\
p(6) = 1/6.  \\
$$
로 정의했었다면 정확이 $p = p_X$가 된다. 
실제로 그렇게 되는지 확인해보는 것이 이제까지의 논의를 정리하는데 많은 도움이 될 것 같다.

요약해보면,  


#### 확률변수 He is the one.



#### 연속의 경우

-> 다음 포스트??

#### 참고자료

[1] A. Shirayaev (translator: D. Chibisov), *Probability- 1*, third edition (2016), Springer.  
[2] 김민형, 확률론의 선과 악: 2. 확률론의 기원 ([네이버티비 동영상](http://tv.naver.com/v/1402550)).  
[3] Mathematical monk, Probability primer ([유튜브 동영상](https://www.youtube.com/watch?v=Tk4ubu7BlSk&list=PL17567A1A3F5DB5E4)).




