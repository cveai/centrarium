---
layout: post
title:  "열개의 팔을 가진 강도"
date:   2018-01-24 00:00:00
author: 장승환
categories: 기계학습
tags: 강화학습 RL
---

"카지노에 가본 적이 있으신가요?" 이 질문에 "그렇습니다!" 하고 답할 사람은 많지 않을 것 같지만 "카지노 로얄"  같은 영화를 본 경험이 있다면 카지노 풍경을 상상하는 것은 그리 어렵지 않을 것이다. 

![alt text](https://cveai.github.io/assets/casino.jpg "Casino Royale")

슬롯머신을 머릿속에 그려보자. 먼저 제일 간단한 경우로, 레버을 당기면 (실제로 그럴리는 없지만) 항상 같은 금액이 나온다고 가정해보자. 이런 경우 이 슬롯머신의 reward(보상)의 분포가 deterministic 하다고 말한다. 레버를 당기기 전에 이미 어떤 금액이 나올지 결정되어 있다는 뜻이다. 이런 경우 한번만 당겨보면 이 슬롯머신에 대해 필요한 모든 정보를 다 아는 것이 된다. 당연히 카지노 측에서 이렇게 만들어 놓을 리가 없다. 실제로는 어떤 확률 분포를 정하고 거기에 맞추어 보상이 결정되도록 프로그램되어 있을 것이다.

슬롯머신의 레버를 당기면  기대값이 0이고 분산이 1인 정규분포(Gaussian distribution, normal distribution)에 따라 숫자를 토해내는 이상적인 상황을 생각하자. 여기서 평균이 0인 분포를 따른다는 것은, 이 슬롯머신의 레버를 당기는 시행을 반복하면서 나오는 숫자들의 평균을 계산해보면 그 시행 횟수가 많아 수록 그 평균이 점점 0에 가까워질 것이라는 것을 의미한다. 

한편, 분산은 시행을 했을 때 기대값에 가까운 값이 나올 가능성의 정도를 나타낸다고 볼 수 있다. 예를 들어 아래 그림으로 표현된 두 분포를 생각해보면 분산이 상대적으로 작은 (a)의 경우... 분산이 큰 (b)

![alt text](https://cveai.github.io/assets/var_small.jpeg "small variance") {: width="30px" height="30px"}
![alt text](https://cveai.github.io/assets/var_large.jpeg "large variance") {: width="30px" height="30px"}
 
또 한가지, 분산이 작은 경우 상대적으로 반복 시행의 평균을 통해 상대적으로 빠르게 기대값에 접근해갈 것임을 알 수 있다. (물론 분산이 큰 경우에도 느기기는 하지만 기대값에 접근해간다.) 이 원리를 이용하면, 슬롯머신이 정규분포를 따르지만 그 기대값을 모르는 경우에도 많은 반복 시행을 통해서 그 분포의 기대값이 얼마인지를 추정해볼 수 있다. 극단적인 경우로 분산이 0인 다음 그림의 분포는 "항상" 그리고 "반드시" 기대값인 0을 주게된다.

그래프

**열개의 팔을 가진 강도**

Multi-armed bandit. 팔 여러개 달린 강도란 뜻이다. 카지노의 슬롯 머신을 가리켜 one armed bandit, 즉 “팔하나 달린 강도”라고 부르는 데서 유래한 용어로, "사실상" 돈을 강탈해간다는 의미에서 그러하다. 

![alt text](https://cveai.github.io/assets/one-armed-bandit.jpg "One-armed banit")

슬롯머신을 생각하자. 이번에는 한 방에 열개의 슬롯머신이 놓여져있다: 1번에서 10번까지 번호가 붙여진 기계들. 이제 agent의 임무는 열개의 머신 중에 하나를 골라 레버를 당기는 시행을 반복하는 것이다. 목표는 반복 시행을 통해 나오는 숫자의 "합"을 최대화하는 것.
