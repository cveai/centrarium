---
layout: post
title:  "Notes on Machine Learning"
date:   2018-03-08 00:00:00
author: 장승환
categories: Notes
tags: ML
---

*In this page I summarize in a succinct and straighforward fashion what I learn from [Machine Learning](https://www.youtube.com/watch?v=yDLKJtOVx5c&list=PLD0F06AA0D2E8FFBA){:target="_blank"} course by Mathematical Monk, along with my own thoughts and related resources.*
*I will update this page frequently, like every other day, until it's complete.*

---

**Acronyms**
* MM: Mathematical Monk
* ML: Machine Learning
* SL: Supervised Learning
* UL: Unsupervised Learning

* MCTC: Markov Chain Monte Carlo

---

#### (ML 1.1) What is machine learning?

"Designing *algorithms* for inferring what is unknown from knowns."

MM considers ML as a subfield of statistics, with emphasis on algorithms.

Got to read an interesting article [Machine Learning vs. Statistics](https://svds.com/machine-learning-vs-statistics/){:target="_blank"}, thanks to [Whi Kwon](https://whikwon.github.io/){:target="_blank"}.

**Applications**
 * Spam (filtering out)
 * Handwriting (recognition)
 * Google streetview
 * Netflix (recommendation systems)
 * Navigation
 * Climate modelling

---

#### (ML 1.2) What is supervised learning?

 Classification of ML problems: Supervised vs. Unsupervised
 
**Supervised**: Given $(x^{(1)}, y^{(1)}), \ldots, (x^{(n)}, y^{(n)})$ choose a *function* $f(x) = y$.
 * Classification: $y^{(i)} \in \\{$finite set$\\}$
 * Regression: $y^{(i)} \in \mathbb{R}$ or $y^{(i)} \in \mathbb{R}^d$

<figure>
<img src="/assets/pics/mm-ml/classification.png" alt="Classification" style="width: 30%; height: 30%">
<figcaption>Classification
</figcaption>
</figure>

<figure>
<img src="/assets/pics/mm-ml/regression.png" alt="Regression" style="width: 70%; height: 70%">
<figcaption>Regression
</figcaption>
</figure>

* $x^{(i)}$ : data point
* $y^{(i)}$ : class/value/label

---

#### (ML 1.3) What is unsupervised learning?

Much less well-defined.

**Unsupervised**: Given $x^{(1)}, \ldots, x^{(n)}$, find *patterns* in the data.
* Clustering (typical UL)
* Density estimation (much more well-defined)
* Dimensionality reduction
* Feature leraning
* many more

<figure>
<img src="/assets/pics/mm-ml/clustering.png" alt="Clustering" style="width: 40%; height: 40%">
<figcaption>Clustering
</figcaption>
</figure>

<figure>
<img src="/assets/pics/mm-ml/de-dr.png" alt="Density estimation and Dimensinality reduction" style="width: 80%; height: 80%">
<figcaption>Density estimation and Dimensinality reduction
</figcaption>
</figure>

---

#### (ML 1.4) Variations on supervised and unsupervised
* Semi-supervised
* Active Learning
* Decision theory
* Reinforcement Learning
 
---

#### (ML 1.5) Generative vs discriminative models

Given data $(x^{(1)}, y^{(1)}), \ldots, (x^{(1)}, y^{(1)})$.  
Denote $(x, y)$ by a prototypical (data point, label) pair.

**Discriminative:** model $p(y\vert x)$ 

**Generative:** model the joint distribution 

$$
\begin{aligned}
p(x, y) &= f(x\vert y)p(y) \\
        &= p(y\vert x)f(x)
\end{aligned}$$

Some good reasons to use discriminative model: 
Statistically, it's very hard to estimate either $f(x\vert y)$ or $f(x)$ because it take a lotof data. (You're inclined to make mistakes.)

Generative process: 

---

#### (ML 1.6) $k$-Nearest Neighbor (kNN) classification algorithm 

Given (a training) data (set) $D = \\{(x_1, y_1), \ldots, (x_n, y_n)\\}$, $x_i \in \mathbb{R}, y_i \in \\{0, 1\\}$ and given a new data point.

Classify by deciding on what is $y$ corresponding to $x$ according to the majority vote from the $k$-nearest points in the training data.

(*Nearest* in terms of a pre-determined metric.)

<figure>
<img src="/assets/pics/mm-ml/knn.png" alt="3NN" style="width: 50%; height: 50%">
<figcaption>3NN in Euclidean metric
</figcaption>
</figure>

**Probabilistic formulation** (<span style="color:red">Discrimitive model!</span>) Fix $D$, $x$, $k$.

Find a RV $Y \sim p$ where $p(y) =$ #$\\{x_i \in N_k(x) : y_i = y \\}/k$ 

Sometimes people write $p(y\vert x, D)$ for $p(y)$.

The estimate (or prediction) is given by 

$$\hat{y} = \arg\max_y p(y\vert x, D).$$

How does one choose $k$? $\rightarrow$ Important problem of choosing parameters. (Bias-variance trade-off)

---

#### (ML 2.1) Classification trees (CART)

CART ([Classification And Regression Trees](https://books.google.co.kr/books/about/Classification_and_Regression_Trees.html?id=JwQx-WOmSyQC&redir_esc=y)) by Breiman et. al.   
(see: https://rafalab.github.io/pages/649/section-11.pdf)

Conceptually very simple approach to classification and regression.  
Can be extremely powerful, specially coupled with some randomizaiton technique, and essentially give the best performance.

**Main idea:** Form a *binary tree* (by binary splits), and *minimize error* in each leaf.

**Example.** (Classification tree)

Data set: $D = ((x_1, y_1), \ldots, (x_n, y_n))$ ($x_i \in \mathbb{R}^2, y \in \\{0, 1\\}$. 

New data point: <span style="color:green">$x$</span>

<figure>
<img src="/assets/pics/mm-ml/bin-split.png" alt="Binary splits for classitication tree" style="width: 50%; height: 50%">
<figcaption>Binary splits for classitication tree
</figcaption>
</figure>

<figure>
<img src="/assets/pics/mm-ml/bin-tree.png" alt="Binary classitication tree" style="width: 80%; height: 80%">
<figcaption>Binary classitication tree
</figcaption>
</figure>

The process defines a function <span style="color:green">$y = f(x)$</span> that is *constant* on each of the petitioned regions.

---

#### (ML 2.2) Regression trees (CART)

Regression tree ($x_i \in \mathbb{R}, y_i \in \mathbb{R}$)

<figure>
<img src="/assets/pics/mm-ml/bin-reg-split.png" alt="Binary splits for regression tree" style="width: 50%; height: 50%">
<figcaption>Binary splits for regression tree
</figcaption>
</figure>

$$\hat{y} = \arg\max_y \sum_{i \in R_1}(y - y_i)^2$$

$\Rightarrow \hat{y} =$ average of the $y_i$'s

<figure>
<img src="/assets/pics/mm-ml/bin-reg-tree.png" alt="Binary regression tree" style="width: 80%; height: 80%">
<figcaption>Binary regression tree
</figcaption>
</figure>

The process defines a function <span style="color:green">$y = f(x)$</span> that is *piecewise constant*.

---

$\cdots$

---

#### (ML 3.5) The Big Picture (part 1)

**Problem:** Minimize 

$${\rm EL}(Y, f(X))$$

using the obsrved $p(y\vert x)$ as the key quantity.

* EL: Expected Loss
* $y$: true value
* $f(x)$: our prediction

Core concepts and methods in ML fall out naturally from trying to solve this problem.

Data: $D = ((x_1, y_), \ldots, (x_n, y_n))$

**Discriminative** Estimate $p(y\vert x)$ directly using $D$.
* $k$NN
* Trees
* SVM

**Generative** Estimate $p(y, x)$ using $D$, and then recover $p(y\vert x) = \frac{p(x, y)}{p(x)}$.

**Parameters / Latent variables** $\theta$, consider $p_\theta(x, y) = p(x, y \vert \theta)$

$$p(y\vert x, D) = \int p(y\vert x, \theta, x, D) p(\theta\vert x, D) d\theta$$

<figure>
<img src="/assets/pics/mm-ml/big-picture.png" alt="Big picture" style="width: 80%; height: 80%">
<figcaption>Big picture
</figcaption>
</figure>


---

#### (ML 3.6) The Big Picture (part 2)
1. Exact inference (usually not possible)
* Multivariate Gaussian (very nice), Conjugate priors, Graphical models (us DP)
2. Point estimate of $\theta$ (simplest)
* MLE, MAP (Maximum A Posteriori)  
* Optimization, EM (Expectation Maximization) / Empirical Bayes
3. Deterministic Approximation
* Laplace Approximation, Variational methods, Expextation Propagation
4. Stochastic Approximation
* MCTC (Gibbs sampling, MH), Importance Sampling (Particle filter)

---

#### (ML 3.7) The Big Picture (part 3)

**Density estimation** (Unsupervised)

$D = (X_1, \ldots, X_n), X_i \in \mathbb{R}^d$, iid.

Goal: Estimate the distribution.

---

#### (ML 4.1) Maximum Likelihood Estimation (MLE) (part 1)

Setup: Given data $D = (x_1, \ldots, x_n), x_i \in \mathbb{R}^d$.
 
Assume a set distributions $\\{p_\theta : \theta \in Theta \\}$ on $\mathbb{R}^d$. ()

Assume $D$ is a sample from $X_1, \ldots, X_n ~ p_\theta$, iid for some $\theta \in \Theta$.

Goal: Estimate the true $\theta$ that $D$ comes from.

**Definition.** $\theta_{\rm MLE}$ for $\theta$ if $\theta_{\rm MLE} = \arg \max_{\theta \in \Theta} p(D\vert \theta).$

(more precisely, $p(D \vert \theta_{\rm MLE}) = \max_{\theta \in \Theta}p(D \vert \theta)$)

$p(D \vert \theta) := p(x_1, \ldots, x_n \vert \theta) = \prod_{i = 1}^n p(x_i \vert \theta) = \prod_{i = 1}^n P[X_i = x_i \vert \theta]$

**Remark**  
(1) MLE might not be unique.  
(2) MLE may fail to exist.  

---

#### (ML 17.1) Sampling methods - why sampling, pros and cons

Why sampling?
* For approximate expectations (estimate statistics / posterior infernce i.e. computing probability)
* For visualization

Why expectations?
* Any probability is an expectation: $P[X \in A] = E[I(X \in A)]$.
* Approximation is needed for intractable sums/integrals (can be expressed as expectations)

Pros.
* Easy (both to implement and understand)
* General purpose

Cons.
* Too easy - used inappropriately
* Slow
* Getting "good" samples may be dificult
* Difficult to assess

---

#### (ML 17.2) Monte Carlo methods - A little history

<figure>
<img src="/assets/pics/mm-ml/mc-history.png" alt="A little history of MC" style="width: 80%; height: 80%">
<figcaption>A little history of Monte Carlo methods
</figcaption>
</figure>

---

#### (ML 17.3) Monte Carlo approximation

Goal: Aprroximate $E[f(X)]$, when intractable.

Definition (Monte Carlo estimator): If $X_1, \ldots, X_n \sim p$ iid then 

$$\hat{\mu}_n = \frac{1}{n}\sum_{i=1}^nf(X_i)$$

is a (basic) *Monte Carlo estimator* of $E[f(X)]$ where $X \sim p$. (sample mean)

Remark  
(1) $E[\hat{\mu}_n] = E[f(X)]$ (i.e. $\hat{\mu}_n$ is an unbiased estimator)  
(2) 

---

#### (ML 17.5) Importance sampling - introduction
<span style="color:red">It's not a sampling method but an estimation technique!</span>

It can be though of as a variant of MC estimation.

Recall: MC estimation (by sample mean): 

$$E[f(X)] \approx \frac{1}{n}\sum_{i=1}^nf(X_i)$$

under the BIG assumtion that $X \sim p$ and $X_i \sim p$.

Can we do something similar by drawing samples from an alternative distribution $q$?

Yes, and in some cases you can do much much better!

($p$ density case)

$$E[f(X)] = \int f(x)p(x)dx = \int f(x)\frac{p(x)}{q(x)}p(x)dx \approx \frac{1}{n}\sum_{i=1}^nf(X_i)\frac{p(X_i)}{q(X_i)}$$

holds for all (pdf) $q$ s.t. $q(x)= 0 \Rightarrow p(x) = 0$, i.e., $p$ is absolutely continuous w.r.t. $q$.

<figure>
<img src="/assets/pics/mm-ml/importance-sampling.png" alt="Importance sampling" style="width: 80%; height: 80%">
<figcaption>Importance sampling
</figcaption>
</figure>

---

$$ $$

*To be added..*

---


