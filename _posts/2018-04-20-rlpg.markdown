---
layout: post
title:  "RLPG discussions"
date:   2018-04-20 00:00:00
author: 장승환
categories: 기계학습
tags: 강화학습 RL 
---

 RLPG 그룹 멤버들간의 토론을 통해 이 노트가 만들어지고 있습니다:

[권휘](https://whikwon.github.io/){:target="_blank"} 김경환(부랩짱, 윈짱) 김민지(맥짱) 류주영 박창규 백병인 이규복 이승재 전효정 조동헌(우짱) 이일구(코짱) 정재윤 최윤규

#### Bellman equation

 Bellman equation 은 MDP 형태로 주어진 강화학습 문제에서 임의의 policy $\pi$ 가 주어졌을 때, 이에 해당하는 value 함수 
 $v_\pi: \mathscr{S} \rightarrow \mathbb{R}$ 와 
 $q_\pi: \mathscr{S} \times \mathscr{A} \rightarrow \mathbb{R}$
 가 각각 만족하게 되는 방정식이다.

먼저 state value 함수 $v_\pi$ 의 경우:

$$\begin{aligned}
v_\pi(s) &= \mathbb{E}(G_t \vert S_t = s) \\
&= \mathbb{E}(R_{t+1} + \gamma G_{t+1} \vert S_t = s) \\
&= \mathbb{E}(R_{t+1} \vert S_t = s) + \gamma \,\mathbb{E}_{S_t = s}(G_{t+1}\vert S_{t+1}) \\
&= \mathbb{E}(R_{t+1} \vert S_t = s) + \gamma \,\mathbb{E}_{S_t = s} \, v_\pi(S_{t+1})
\end{aligned}$$


#### $Q$-learning as an off-policy TD learning






#### 참고자료

[1] R. Sutton, A. Barto, *Reinforcement leaning: an introduction*, second edition ([final draft](http://incompleteideas.net/book/the-book-2nd.html){:target="_blank"}).     

---

*읽으시다 오류나 부정확한 내용을 발견하시면 꼭 알려주시길 부탁드립니다. 감사합니다.*  
